{
  "cells": [
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import keras\n",
        "from keras.layers import MaxPooling2D, UpSampling2D\n",
        "from keras.layers import Conv2D, Input, BatchNormalization, Dropout\n",
        "from keras.optimizers import RMSprop\n",
        "from keras.models import Model, load_model\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# from tensorflow.contrib.learn.python.learn.datasets.mnist import extract_images, extract_labels\n",
        "\n",
        "\n",
        "import argparse\n",
        "from mlxtend.data import loadlocal_mnist\n",
        "import platform\n",
        "import math\n",
        "import struct\n",
        "\n",
        "\n",
        "\n",
        "def encoder(input_img, convolutions, filter_size, kernel_size, dropout_size):\n",
        "    #encoder\n",
        "    #input 28 x 28 x 1\n",
        "    conv1 = Conv2D(filter_size[0], (kernel_size[0],kernel_size[0]), activation='relu', padding='same')(input_img) \n",
        "    conv1 = BatchNormalization()(conv1)\n",
        "    conv1 = Conv2D(filter_size[1], (kernel_size[1],kernel_size[1]), activation='relu', padding='same')(conv1)\n",
        "    conv1 = BatchNormalization()(conv1)\n",
        "    model = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
        "    for i in range(2, convolutions-1, 2):\n",
        "        model = Conv2D(filter_size[i], (kernel_size[i],kernel_size[i]), activation='relu', padding='same')(model) \n",
        "        model = BatchNormalization()(model)\n",
        "        model = Conv2D(filter_size[i+1], (kernel_size[i+1],kernel_size[i+1]), activation='relu', padding='same')(model)\n",
        "        model = BatchNormalization()(model)\n",
        "        if (i == 2):\n",
        "            model = MaxPooling2D(pool_size=(2, 2))(model) \n",
        "        model = Dropout(dropout_size[i+1])(model)    \n",
        "        print(dropout_size[i+1])\n",
        "    if (convolutions%2 != 0):\n",
        "        model = Conv2D(filter_size[convolutions-1], (kernel_size[convolutions-1],kernel_size[convolutions-1]), activation='relu', padding='same')(model)\n",
        "        model = BatchNormalization()(model)\n",
        "\n",
        "    return model\n",
        "\n",
        "def decoder(model, convolutions, filter_size, kernel_size, dropout_size):\n",
        "    #decoder\n",
        "    if (convolutions%2 != 0):\n",
        "        model = Conv2D(filter_size[convolutions-1], (kernel_size[convolutions-1],kernel_size[convolutions-1]), activation='relu', padding='same')(model)\n",
        "        model = BatchNormalization()(model)\n",
        "        model = Conv2D(filter_size[convolutions-2], (kernel_size[convolutions-2],kernel_size[convolutions-2]), activation='relu', padding='same')(model) \n",
        "        model = BatchNormalization()(model)\n",
        "        model = Conv2D(filter_size[convolutions-3], (kernel_size[convolutions-3],kernel_size[convolutions-3]), activation='relu', padding='same')(model)\n",
        "        model = BatchNormalization()(model)\n",
        "        if (convolutions==5):\n",
        "            model = UpSampling2D((2,2))(model)\n",
        "        model = Dropout(dropout_size[convolutions-3])(model)    \n",
        "\n",
        "        for i in range(convolutions-4 , -1, -2):\n",
        "            model = Conv2D(filter_size[i], (kernel_size[i],kernel_size[i]), activation='relu', padding='same')(model) \n",
        "            model = BatchNormalization()(model)\n",
        "            model = Conv2D(filter_size[i-1], (kernel_size[i-1],kernel_size[i-1]), activation='relu', padding='same')(model)\n",
        "            model = BatchNormalization()(model)\n",
        "            if (i == 1 or i == 3):\n",
        "                model = UpSampling2D((2,2))(model) \n",
        "            if(i != 1):\n",
        "                model = Dropout(dropout_size[i-1])(model) \n",
        "\n",
        "        model = Conv2D(1, (kernel_size[0],kernel_size[0]), activation='sigmoid', padding='same')(model)\n",
        "    else:\n",
        "        model = Conv2D(filter_size[convolutions-1], (kernel_size[convolutions-1],kernel_size[convolutions-1]), activation='relu', padding='same')(model) \n",
        "        model = BatchNormalization()(model)\n",
        "        model = Conv2D(filter_size[convolutions-2], (kernel_size[convolutions-2],kernel_size[convolutions-2]), activation='relu', padding='same')(model)\n",
        "        model = BatchNormalization()(model)\n",
        "        if (convolutions==4):\n",
        "            model = UpSampling2D((2,2))(model)\n",
        "        model = Dropout(dropout_size[convolutions-1])(model)   \n",
        "        for i in range(convolutions-3 , -1, -2):\n",
        "            model = Conv2D(filter_size[i], (kernel_size[i],kernel_size[i]), activation='relu', padding='same')(model) \n",
        "            model = BatchNormalization()(model)\n",
        "            model = Conv2D(filter_size[i-1], (kernel_size[i-1],kernel_size[i-1]), activation='relu', padding='same')(model)\n",
        "            model = BatchNormalization()(model)\n",
        "            if (i == 1 or i==3):\n",
        "                model = UpSampling2D((2,2))(model) \n",
        "            if(i != 1):\n",
        "                model = Dropout(dropout_size[i])(model)  \n",
        "        \n",
        "        model = Conv2D(1, (kernel_size[0],kernel_size[0]), activation='sigmoid', padding='same')(model)\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    # reading the mnist files\n",
        "    parser = argparse.ArgumentParser()\n",
        "\n",
        "    parser.add_argument(\"--file\", \"-d\", type=str, required=True)\n",
        "    args = parser.parse_args() \n",
        "    # Dataset is save in args.file\n",
        "\n",
        "    \n",
        "    with open(args.file, 'rb') as imgpath:\n",
        "        magic, num, rows, cols = struct.unpack(\">IIII\",imgpath.read(16))\n",
        "        X = np.fromfile(imgpath,dtype=np.uint8).reshape(num, 784)\n",
        "    \n",
        "    print('%s images with dimension: %s' % (X.shape[0],X.shape[1]))\n",
        "    number_of_images = int(X.shape[0])\n",
        "    dimensions = int(X.shape[1])\n",
        "    part = input(\"Type 'part' to use a part of your dataset: \")\n",
        "    if(part == \"part\"):\n",
        "        part = input(\"Type the number of images you want to train: \")\n",
        "        part = int(part)\n",
        "        if(part>number_of_images):\n",
        "            print('You typed more images than expected. We will work with whole dataset.')\n",
        "        else:\n",
        "            number_of_images = part\n",
        "\n",
        "\n",
        "    history_list = []\n",
        "\n",
        "    while(1):\n",
        "\n",
        "        # Define the convolutional Autoencoder Model\n",
        "        x, y = int(math.sqrt(dimensions)), int(math.sqrt(dimensions))\n",
        "        CNN_convs = 8\n",
        "        filters_size_list = [32,32,64,64,128,128,256,256]\n",
        "        kernel_size_list = [3,3,3,3,3,3,3,3]\n",
        "        dropout_list = [0,0.05,0,0.05,0,0.05,0,0.05]\n",
        "        create = input(\"Type 'create' if you want to create your own model: \")\n",
        "        if(create == 'create'):\n",
        "            filters_size_list.clear()\n",
        "            kernel_size_list.clear()\n",
        "            dropout_list.clear()\n",
        "            print('###################################################################################################################')\n",
        "            print(\"The CNN model has blocks of: 2 convolutions, each followed by 1 BatchNormalization and after that, \\n1 Dropout layer, except the first block which doesnt have Dropout after it.\")\n",
        "            print(\"The first 2 blocks are also followed by 2 downsampling layers, so that the final image-layer has shape %s x %s\" %(x/4 , y/4))\n",
        "            print('###################################################################################################################')\n",
        "            CNN_convs = input (\"Type the number of convolutions you want: \")\n",
        "            CNN_convs = int(CNN_convs)\n",
        "            while(CNN_convs < 4):\n",
        "                CNN_convs = input (\"Type the number of convolutions you want (at least 4 needed): \")\n",
        "                CNN_convs = int(CNN_convs)\n",
        "\n",
        "            for i in range(0, CNN_convs):\n",
        "                filter_size = input (\"Type the number of filter in Convolution(%d): \" %(i+1))\n",
        "                filters_size_list.append( int(filter_size) )\n",
        "                kernel_size = input (\"Type the kernel size of Convolution(%d): \" %(i+1))\n",
        "                kernel_size_list.append( int(kernel_size) )\n",
        "                if (i%2 == 1 and i!=1):\n",
        "                    dropout_size = input (\"Type the dropout size (0.xx) after Convolution(%d): \" %(i+1))\n",
        "                    dropout_list.append( float(dropout_size))\n",
        "                else:\n",
        "                    dropout_list.append(0)\n",
        "\n",
        "\n",
        "        inChannel =  input(\"inChannel: \")\n",
        "        batch_size = input(\"Batch Size: \") #128 stis diafaneies\n",
        "        epochs = input(\"Epochs: \")\n",
        "        inChannel = int(inChannel)\n",
        "        batch_size = int(batch_size)\n",
        "        epochs = int(epochs)\n",
        "        input_img =  Input(shape=(x, y, inChannel), name='input')\n",
        "\n",
        "        train_X = np.reshape(X, (len(X), 28, 28, 1))\n",
        "        train_X = train_X.astype('float32')\n",
        "        train_X = train_X/255.0\n",
        "        autoencoder = Model(input_img, decoder(encoder(input_img,CNN_convs, filters_size_list, kernel_size_list, dropout_list), CNN_convs, filters_size_list, kernel_size_list, dropout_list))\n",
        "        trained = input(\"Type 'pre' to use pretrained model: \")\n",
        "        if(trained == 'pre'):       #option to use pretrained model\n",
        "            model_path = input(\"Give me the path to pretrained model: \")\n",
        "            model = load_model(model_path)\n",
        "            weights = model.get_weights()\n",
        "            for m1, m2 in zip(autoencoder.layers[:], model.layers[:]):\n",
        "                m1.set_weights(m2.get_weights())\n",
        "        autoencoder.compile(loss='mean_squared_error', optimizer = RMSprop()) #RMSprop() stis diafaneies\n",
        "        #autoencoder.summary() #uncomment to see the summary of the model\n",
        "\n",
        "        #train_X = preprocess(train_X)\n",
        "        train_X = train_X[:number_of_images] # uncomment if you want less images\n",
        "        train_X, valid_X, train_ground, valid_ground = train_test_split(train_X,train_X,test_size=0.2, random_state=13)\n",
        "        #print('Dimensions: %s x %s' % (train_X.shape[0],train_X.shape[1]))\n",
        "        filters = (','.join(str(x) for x in filters_size_list))\n",
        "        kernel = (','.join(str(x) for x in kernel_size_list))\n",
        "        drops = (','.join(str(x) for x in dropout_list))\n",
        "\n",
        "\n",
        "        history = autoencoder.fit(train_X, train_ground, batch_size = batch_size,epochs = epochs,verbose=1, validation_data=(valid_X,valid_ground))\n",
        "        history_list.append((history,batch_size,inChannel,epochs, CNN_convs, filters, kernel, drops))\n",
        "        pl = input(\"Type 'yes' to plot: \")\n",
        "        if(pl == 'yes'):\n",
        "\n",
        "            for history in history_list:\n",
        "                #summarize history for loss\n",
        "                plt.plot(history[0].history['loss'], label= 'train loss')\n",
        "                plt.plot(history[0].history['val_loss'], label= 'val loss')\n",
        "                plt.title('Convolutions: %d\\nFilters: %s\\nKernel size: %s\\nDropout: %s' %(history[4], history[5], history[6], history[7]), loc='left')\n",
        "                plt.ylabel('Loss')\n",
        "                plt.xlabel('Epochs')\n",
        "    #            plt.legend(['train_loss', 'val_loss'], loc='upper left')\n",
        "                filters = 32\n",
        "                plt.title('Batches: %d\\ninChannell: %d\\nEpochs: %d' %(history[1], history[2], history[3]), loc='right')\n",
        "                plt.legend()\n",
        "                plt.show()\n",
        "        \n",
        "        next_move = input(\"Type 'save' to save: \")\n",
        "        if(next_move == 'save'):\n",
        "            path = input(\"Give me the path to save the previous autoencoder model: \")\n",
        "            autoencoder.save(path)\n",
        "\n",
        "        next_move = input(\"Type '0' to stop: \")\n",
        "        if(next_move == '0'):\n",
        "            quit()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}